{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c77f4f0a",
   "metadata": {},
   "source": [
    "Deep Q Learning model - Based on a Neural Network\n",
    "\n",
    "We use gradient descent to match the predicted Q-values to the result of those actions.\n",
    "The closer we get to 0, the better the model is performing.\n",
    "The goal is for the prediction to always match the result. That is achieved by getting the global minimum.\n",
    "\n",
    "$ Q(s, a) $ - *Action value function*\n",
    "\n",
    "Or said simply... *Expected cumulative reward from state **s** by taking action **a***.\n",
    "\n",
    "Where:\n",
    "\n",
    "Q = Quality of action\n",
    "\n",
    "s = state\n",
    "\n",
    "a = action\n",
    "\n",
    "$ Q^target(s, a) = R + \\gamma.((max(Q(s', a'))) / 2) $\n",
    "\n",
    "\n",
    "Each move the model outputs 3 possible actions.\n",
    "Then the agent picks the one with the highest Q-value.\n",
    "\n",
    "State - A vector of many bool values\n",
    "\n",
    "**Bellman Equation** for Double Q-Learning: $$ NewQ(s, a) = Q(s, a) + \\alpha[R(s, a) + \\gamma maxQ'(s', a') - Q(s, a)] $$\n",
    "\n",
    "We modify the base equation to reduce overestimation.\n",
    "\n",
    "Our loss function is $$(Q_{new} - Q)^2$$\n",
    "\n",
    "\n",
    "In pygame the coordinate system works differently... instead of y growing by going up vertically,([0, 0] is not in the middle of the screen, but it's on the top left edge) it grows down, this is done to mimic the pixels in our monitors.\n",
    "\n",
    "$ \\gamma $ or **Gamma** controls how much the agent values future rewards compared to immediate rewards. $ \\gamma = 0 $ means we only care about immediate rewards. $ \\gamma = 1$ values distant future rewards equally.\n",
    "\n",
    "**Key insight:** Higher gamma -> more strategic/long-term thinking (but learns slower)\n",
    "\n",
    "A **tensor** is a generalized data type used by reinforcement learning models _(such as Pytorch)_ to represent and process all kinds of numerical data, such as states, actions, and rewards.\n",
    "\n",
    "To start training, in the **Agent** - **train** method we turn off both *load_previous* and *continue_training*. To load a model and continue training we turn both of them **ON**. And to just run a trained model we turn *load_previous* to **True** and *continue_training* to **False**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a5595",
   "metadata": {},
   "source": [
    "### Resources:\n",
    "\n",
    "https://www.youtube.com/watch?v=PJl4iabBEz0&list=PLfR10wejCzo_OL-6OsBV-4jAPnSncvZZH\n",
    "\n",
    "https://en.wikipedia.org/wiki/Reinforcement_learning\n",
    "\n",
    "https://www.geeksforgeeks.org/what-is-reinforcement-learning/\n",
    "\n",
    "https://www.geeksforgeeks.org/snake-game-in-python-using-pygame-module/\n",
    "\n",
    "https://pytorch.org/\n",
    "\n",
    "https://www.pygame.org/docs/\n",
    "\n",
    "https://docs.pytorch.org/docs/stable/tensors.html\n",
    "\n",
    "\n",
    "\n",
    "And of course... **ChatGPT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589ae516",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "\n",
    "Maybe move the BLOCK_SIZE and SPEED of game.py in the Snake class so we can use it in the agent directly.\n",
    "\n",
    "Maybe even inject it from the controller so we can dynamically change it in the future... not sure tho.\n",
    "\n",
    "Finish the ipynb file for the project, explain everything and so on...\n",
    "\n",
    "Implement saving and importing the trained model.\n",
    "\n",
    "Make display bigger... maybe?\n",
    "\n",
    "Като предавам да питам Данчо какво правим със самоуценката. Дали по-рано да се попълни или...?\n",
    "\n",
    "Test if the game can be ran in jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e518b0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNAKE_GAME_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
